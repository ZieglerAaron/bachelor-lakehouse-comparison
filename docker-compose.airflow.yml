version: '3.8'
services:
  airflow:
    image: apache/airflow:2.8.1-python3.10
    restart: always
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__FERNET_KEY=airflowfernetkeyairflowfernetkey
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__SECRET_KEY=airflowsecretkeyairflowsecretkey
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
      - AIRFLOW__WEBSERVER__PORT=8081
    ports:
      - "8081:8081"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./airflow/requirements.txt:/requirements.txt
      - ./delta/spark-apps:/opt/spark-apps
      - ./delta/spark-extra-jars:/opt/spark/extra-jars
    depends_on: []
    command: >
      bash -c "
        pip install --no-cache-dir -r /requirements.txt &&
        airflow db upgrade &&
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com &&
        airflow webserver --port 8081
      "
    networks:
      - lakehouse
networks:
  lakehouse:
    external: true 